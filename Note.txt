curl -i -X POST -H "Accept:application/json" -H "Content-Type:application/json" http://localhost:8083/connectors -d '{ "name": "debezium-connector", 
"config": { 
    "connector.class": "io.debezium.connector.sqlserver.SqlServerConnector",
    "database.hostname": "host.docker.internal", 
    "database.port": "1433", 
    "database.user": "anan",
    "database.password": "anan", 
    "database.dbname": "Test_DB", 
    "database.names":"Test_DB",
    "database.server.name": "host.docker.internal", 
    "table.whitelist": "dbo.prospects", 
    "topic.prefix": "fullfillment",
    "database.history.kafka.bootstrap.servers": "kafka1:29092", 
    "database.history.kafka.topic": "schema-changes-topic",
    "errors.log.enable": "true",
    "schema.history.internal.kafka.bootstrap.servers": "kafka1:29092",  
    "schema.history.internal.kafka.topic": "schema-changes.inventory",
    "database.trustServerCertificate": true  } 
}';


===============================================================================================================================================================

CREATE DATABASE Test_DB;
GO
USE Test_DB;
EXEC sys.sp_cdc_enable_db;ALTER DATABASE Test_DB
SET CHANGE_TRACKING = ON
(CHANGE_RETENTION = 2 DAYS, AUTO_CLEANUP = ON)


CREATE TABLE prospects (
  id INTEGER IDENTITY(1001,1) NOT NULL PRIMARY KEY,
  first_name VARCHAR(255) NOT NULL,
  last_name VARCHAR(255) NOT NULL,
  email VARCHAR(255) NOT NULL UNIQUE
);

EXEC sys.sp_cdc_enable_table @source_schema = 'dbo', @source_name = 'prospects', @role_name = NULL, @supports_net_changes = 0;
GO

===============================================================================================================================================================
# Install AirFlow
1.  curl -LfO 'https://airflow.apache.org/docs/apache-airflow/2.10.5/docker-compose.yaml'

2.  
    ENDPOINT_URL="http://localhost:8082"
    curl -X GET \
        --user "airflow:airflow" \
        "${ENDPOINT_URL}/api/v1/pools"

    OR

    curl -v --user "airflow:airflow" http://localhost:8082/api/v1/pools



=========================================================================================================

#!/bin/bash

# === Register Debezium SQL Server Source Connector ===
echo "üì° Registering Debezium connector with Kafka Connect..."

curl -i -X POST -H "Accept:application/json" -H "Content-Type:application/json" \
http://localhost:8083/connectors -d '{
  "name": "debezium-connector",
  "config": {
    "connector.class": "io.debezium.connector.sqlserver.SqlServerConnector",
    "database.hostname": "host.docker.internal",
    "database.port": "1433",
    "database.user": "anan",
    "database.password": "anan",
    "database.dbname": "Test_DB",
    "database.names": "Test_DB",
    "database.server.name": "host.docker.internal",
    "table.whitelist": "dbo.prospects",
    "topic.prefix": "fullfillment",
    "database.history.kafka.bootstrap.servers": "kafka1:29092",
    "database.history.kafka.topic": "schema-changes-topic",
    "schema.history.internal.kafka.bootstrap.servers": "kafka1:29092",
    "schema.history.internal.kafka.topic": "schema-changes.inventory",
    "errors.log.enable": "true",
    "database.trustServerCertificate": "true"
  }
}'

echo -e "\n‚úÖ Debezium connector registered.\n"

# === Airflow: List Pools ===
echo "üå¨Ô∏è  Checking Airflow pools via API..."

curl -v --user "airflow:airflow" http://localhost:8082/api/v1/pools

echo -e "\n‚úÖ Airflow API call completed."
